# Fashion_MNIST_Classifier

# í‹°ì…”ì¸ , ìš´ë™í™”, ë“±ë“± íŒ¨ì…˜ ì•„ì´í…œ ë¶„ë¥˜

import numpy as np
import random
import tensorflow as tf

# 1. [ì‹œë“œ ê³ ì •] ì¬í˜„ì„±ì„ ìœ„í•´ ëœë¤ ì‹œë“œ ê³ ì •
random.seed(777)
tf.random.set_seed(777)

# 2. [í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹]
# í•™ìŠµë¥ ì„ ë‚®ì¶°ì„œ(0.0005) ë” ì •ë°€í•˜ê²Œ í•™ìŠµ
learning_rate = 0.0005  
batch_size = 100
training_epochs = 15
nb_classes = 10
# ì€ë‹‰ì¸µì˜ ë‰´ëŸ° ìˆ˜ë¥¼ 512ë¡œ ëŠ˜ë ¤ì„œ ë³µì¡í•œ íŒ¨í„´ ìˆ˜ìš© ëŠ¥ë ¥ í™•ëŒ€
hidden_units = 512      

# Fashion MNIST í´ë˜ìŠ¤ ì´ë¦„ (ì¶œë ¥ í™•ì¸ìš©)
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# 3. [ë°ì´í„° ë¡œë“œ] Fashion MNIST ë°ì´í„°ì…‹ ì‚¬ìš©
# ì¸í„°ë„·ì—ì„œ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ ë°›ìŠµë‹ˆë‹¤.
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()

# 4. [ë°ì´í„° ì „ì²˜ë¦¬]
# (1) 2ì°¨ì›(28x28) -> 1ì°¨ì›(784) í‰íƒ„í™”
x_train = x_train.reshape(x_train.shape[0], 28 * 28)
x_test = x_test.reshape(x_test.shape[0], 28 * 28)

# (2) ì •ê·œí™” (Normalization) - [ì¤‘ìš”]
# ì§€ë‚œë²ˆ ì˜ˆì œì—ì„œ ì´ˆê¸° lossê°€ í­ë°œí–ˆë˜ ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ 0~1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë³€í™˜
x_train = x_train / 255.0
x_test = x_test / 255.0

# (3) ì›-í•« ì¸ì½”ë”© (One-hot Encoding)
y_train = tf.keras.utils.to_categorical(y_train, nb_classes)
y_test = tf.keras.utils.to_categorical(y_test, nb_classes)

# 5. [ëª¨ë¸ êµ¬ì„±] ì‹¬ì¸µ ì‹ ê²½ë§ (Deep & Wide)
tf.model = tf.keras.Sequential()

# ì€ë‹‰ì¸µ 1: ë‰´ëŸ° 512ê°œ (ìš©ëŸ‰ ì¦ê°€)
tf.model.add(tf.keras.layers.Dense(input_dim=784, units=hidden_units, activation='relu'))

# ì€ë‹‰ì¸µ 2: ë‰´ëŸ° 512ê°œ (ê¹Šì´ ìœ ì§€)
tf.model.add(tf.keras.layers.Dense(units=hidden_units, activation='relu'))

# ì¶œë ¥ì¸µ: 10ê°œ ë¶„ë¥˜
tf.model.add(tf.keras.layers.Dense(units=nb_classes, activation='softmax'))

# 6. [ì»´íŒŒì¼]
tf.model.compile(loss='categorical_crossentropy',
                 optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                 metrics=['accuracy'])
tf.model.summary()

# 7. [í•™ìŠµ ìˆ˜í–‰]
print("ğŸ‘— íŒ¨ì…˜ ì•„ì´í…œ ë¶„ë¥˜ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
history = tf.model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)

# 8. [ëœë¤ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸]
y_predicted = tf.model.predict(x_test)
print("\n" + "="*50)
print("ğŸ” ëœë¤ ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸")
print("="*50)

for x in range(0, 10):
    random_index = random.randint(0, x_test.shape[0]-1)
    
    actual_label = np.argmax(y_test[random_index])
    predicted_label = np.argmax(y_predicted[random_index])
    
    # ê²°ê³¼ ì¶œë ¥ (ìˆ«ì ëŒ€ì‹  ì˜· ì´ë¦„ìœ¼ë¡œ ì¶œë ¥)
    print(f"Index: {random_index:<5} | "
          f"ì •ë‹µ: {class_names[actual_label]:<12} vs "
          f"ì˜ˆì¸¡: {class_names[predicted_label]:<12} -> "
          f"{'âœ… ì •ë‹µ' if actual_label == predicted_label else 'âŒ ì˜¤ë‹µ'}")

# 9. [ìµœì¢… í‰ê°€]
evaluation = tf.model.evaluate(x_test, y_test, verbose=0)
print("="*50)
print(f"ìµœì¢… Loss: {evaluation[0]:.4f}")
print(f"ìµœì¢… Accuracy: {evaluation[1]*100:.2f}%")
#===================================================================
# ë‹¨ìˆœí•œ ì†ê¸€ì”¨ì—ì„œ íŒ¨ì…˜ ì•„ì´í…œìœ¼ë¡œ ëŒ€ìƒì„ í™•ì¥
# í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹: unitì˜ ê°œìˆ˜(ë‰´ëŸ° ìˆ˜) 2ë°° ì¦ê°€, í•™ìŠµë¥  ì ˆë°˜ìœ¼ë¡œ ê°ì†Œ

# ì²«ë²ˆì§¸ ì—í¬í¬ì˜ lossê°€ 0.4904ë¡œ ì‹œì‘ -> ë°ì´í„° ì „ì²˜ë¦¬ê°€ ì˜ ì´ë£¨ì–´ì¡Œë‹¤.
# ë§ˆì§€ë§‰ ì—í¬í¬ì—ì„œ í•™ìŠµ ì •í™•ë„ê°€ 94.64%ê¹Œì§€ ë„ë‹¬
# ì‹¤ì „ í…ŒìŠ¤íŠ¸ ì ìˆ˜ 87.2%ë¡œ í•™ìŠµ ì ìˆ˜ì™€ì˜ ì˜¤ì°¨ê°€ ë°œìƒ (ê³¼ì í•© ê°€ëŠ¥ì„±)

# ë³µì¡í•œ ë°ì´í„°ë¥¼ ìƒíƒœë¡œ ì¤€ìˆ˜í•œ ì„±ì ì„ ê±°ë‘ì—ˆìœ¼ë‚˜ í•™ìŠµ ë°ì´í„°ì™€ì˜ ê²©ì°¨ë¥¼ ì¤„ì—¬ì•¼í•œë‹¤.

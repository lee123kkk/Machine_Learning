# Lab 6 Softmax Classifier
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

# ê²°ê³¼ ì¬í˜„ì„ ìœ„í•œ ì‹œë“œ ê³ ì •
tf.random.set_seed(777)

# 1. [ë°ì´í„° ì¤€ë¹„]
# x_data: [ê³µë¶€ ì‹œê°„, ì¶œì„ ìˆ˜]
x_data = [[10, 5],
          [9, 5],
          [3, 2],
          [2, 4],
          [11, 1]]

# y_data: [Aë“±ê¸‰, Bë“±ê¸‰, Cë“±ê¸‰] (ì›-í•« ì¸ì½”ë”© ë¨)
# [1, 0, 0] -> A
# [0, 1, 0] -> B
# [0, 0, 1] -> C
y_data = [[1, 0, 0],
          [1, 0, 0],
          [0, 1, 0],
          [0, 1, 0],
          [0, 0, 1]]

x_data = np.array(x_data, dtype=np.float32)
y_data = np.array(y_data, dtype=np.float32)

# í´ë˜ìŠ¤ ê°œìˆ˜ (3ê°œ: A, B, C)
nb_classes = 3

# 2. [ëª¨ë¸ êµ¬ì„±]
model = tf.keras.Sequential()
# ì…ë ¥ 2ê°œ -> ì¶œë ¥ 3ê°œ (Softmax)
# í¸í–¥(bias)ë„ ì‚¬ìš©í•˜ê² ë‹¤ê³  ëª…ì‹œ (use_bias=True)
model.add(tf.keras.layers.Dense(units=nb_classes, input_dim=2, activation='softmax'))

# 3. [ì»´íŒŒì¼]
# ì›-í•« ì¸ì½”ë”© ë°ì´í„°ì´ë¯€ë¡œ categorical_crossentropy ì‚¬ìš©
model.compile(loss='categorical_crossentropy',
              optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),
              metrics=['accuracy'])

# 4. [í•™ìŠµ]
print("ğŸ¨ ì¸ê³µì§€ëŠ¥ì´ ë•…ë”°ë¨¹ê¸° ì§€ë„ë¥¼ ê·¸ë¦¬ê³  ìˆìŠµë‹ˆë‹¤...")
history = model.fit(x_data, y_data, epochs=2000, verbose=0)
print("âœ… í•™ìŠµ ì™„ë£Œ!")

# ==========================================================
# 5. [ì‹œê°í™”] ê²°ì • ê²½ê³„(Decision Boundary) ê·¸ë¦¬ê¸°
# ==========================================================

# (1) ê·¸ë˜í”„ì˜ ë²”ìœ„ ì„¤ì • (ë°ì´í„°ë³´ë‹¤ ì¡°ê¸ˆ ë” ë„“ê²Œ ì¡ìŒ)
x_min, x_max = x_data[:, 0].min() - 1, x_data[:, 0].max() + 1
y_min, y_max = x_data[:, 1].min() - 1, x_data[:, 1].max() + 1

# (2) ë°”ë‘‘íŒ(Meshgrid) ë§Œë“¤ê¸°: 0.1 ê°„ê²©ìœ¼ë¡œ ì´˜ì´˜í•˜ê²Œ ì¢Œí‘œ ìƒì„±
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),
                     np.arange(y_min, y_max, 0.1))

# (3) ë°”ë‘‘íŒ ìœ„ì˜ ëª¨ë“  ì ì— ëŒ€í•´ ì˜ˆì¸¡í•˜ê¸°
# ì´˜ì´˜í•œ ì ë“¤ì„ ëª¨ë¸ì— ë„£ì–´ì„œ Aì¸ì§€, Bì¸ì§€, Cì¸ì§€ ë¬¼ì–´ë´…ë‹ˆë‹¤.
# ravel()ì€ 2ì°¨ì› í–‰ë ¬ì„ 1ì¤„ë¡œ í´ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
grid_points = np.c_[xx.ravel(), yy.ravel()]
pred_probs = model.predict(grid_points, verbose=0)

# ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ ë²ˆí˜¸(0, 1, 2)ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
pred_labels = np.argmax(pred_probs, axis=1)

# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ë°”ë‘‘íŒ ëª¨ì–‘ìœ¼ë¡œ ë³µêµ¬í•©ë‹ˆë‹¤.
Z = pred_labels.reshape(xx.shape)

# (4) ë“±ê³ ì„ (Contour) ê·¸ë¦¬ê¸°
plt.figure(figsize=(10, 6))

# ì˜ì—­ ì¹ í•˜ê¸° (ë°°ê²½ìƒ‰)
# cmap='coolwarm' ë“± ë‹¤ì–‘í•œ ì»¬ëŸ¬ë§µ ì‚¬ìš© ê°€ëŠ¥
plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Spectral)

# (5) ì‹¤ì œ ë°ì´í„° ì  ì°ê¸°
class_names = {0: 'Class A', 1: 'Class B', 2: 'Class C'}
colors = ['red', 'blue', 'green']

# ì •ë‹µ(y_data)ì„ ìˆ«ìë¡œ ë³€í™˜ (ì›-í•« -> 0, 1, 2)
y_label = np.argmax(y_data, axis=1)

for i in range(nb_classes):
    # í•´ë‹¹ í´ë˜ìŠ¤ì¸ ë°ì´í„°ë§Œ ê³¨ë¼ë‚´ê¸°
    idx = (y_label == i)
    plt.scatter(x_data[idx, 0], x_data[idx, 1], 
                c=colors[i], 
                s=100, 
                edgecolors='k', 
                label=class_names[i])

# (6) í•™ìŠµëœ ê°€ì¤‘ì¹˜(W)ì™€ í¸í–¥(b) ìˆ˜ì‹ í‘œì‹œí•˜ê¸°
# ëª¨ë¸ ë‚´ë¶€ì˜ íŒŒë¼ë¯¸í„°ë¥¼ êº¼ë‚´ì˜µë‹ˆë‹¤.
weights = model.layers[0].get_weights()
W = weights[0] # ê°€ì¤‘ì¹˜ (2x3 í–‰ë ¬)
b = weights[1] # í¸í–¥ (3ê°œ)

print("\n--- í•™ìŠµëœ ìˆ˜ì‹ íŒŒë¼ë¯¸í„° ---")
for i in range(nb_classes):
    # ê° í´ë˜ìŠ¤ë³„ë¡œ í•™ìŠµëœ ì§ì„ ì˜ ë°©ì •ì‹ ê³„ìˆ˜
    w1 = W[0, i]
    w2 = W[1, i]
    bias = b[i]
    print(f"[{class_names[i]}] Score = ({w1:.2f})*x1 + ({w2:.2f})*x2 + ({bias:.2f})")
    
    # ë²”ë¡€ì— ìˆ˜ì‹ ì¶”ê°€ (ê·¸ë˜í”„ êµ¬ì„ì— í‘œì‹œ)
    plt.plot([], [], ' ', label=f'{class_names[i]}: {w1:.2f}x1 + {w2:.2f}x2 + {bias:.2f}')

plt.xlabel('Study Hours (x1)')
plt.ylabel('Attendance (x2)')
plt.title('Softmax Decision Boundaries (3 Classes)')
plt.legend(loc='lower right')
plt.show()
    

    # # 3D plot
    # fig = plt.figure()
    # ax = fig.add_subplot(111, projection='3d')
    # ax.contour3D(xx1, xx2, h, 50, cmap='binary')
    # for i in range(3):
    #     ax.scatter(x_data[np.argmax(y_data, axis=1) == i, 0], x_data[np.argmax(y_data, axis=1) == i, 1], np.argmax(y_data, axis=1)[np.argmax(y_data, axis=1) == i], label=f'Class: {label[i]}', s=100, edgecolors='r', alpha=0.5)
    # ax.set_xlabel('X1(hour)')
    # ax.set_ylabel('X2(attendance)')
    # ax.set_zlabel('Class')
    # ax.set_title('Decision Boundaries')
    # ax.legend()          
    
    # plt.show()
#================================================================
# ì†Œí”„íŠ¸ë§¥ìŠ¤ ë¶„ë¥˜ê¸°ì˜ ê²°ì •ê²½ê³„ ì‹œê°í™”
# ì†Œí”„íŠ¸ë§¥ìŠ¤ ë¶„ë¥˜ê¸°ëŠ” ì—¬ë ¤ ê°œì˜ ì§ì„  ë°©ì •ì‹ì„ ë™ì‹œì— í•™ìŠµí•˜ì—¬ ë°ì´í„° ê³µê°„ì„ ê° í´ë˜ìŠ¤ê°€ ì ìœ í•˜ëŠ” êµ¬ì—­ìœ¼ë¡œ ê¹”ë”í•˜ê²Œ ë¶„í• í•œë‹¤.
# 
#TFDS_CIFAR10_Xavier_Visual

'''
Xavierì´ˆê¸°í™”ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë°ì´í„° ì…‹ì„ TFDS ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ êµì²´
CIRAR-10 ë°ì´í„° ì‚¬ìš© (32X32 ì»¬ëŸ¬, ì‚¬ë¬¼ 10ì¢…)
'''

import tensorflow as tf
import tensorflow_datasets as tfds  # TFDS ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
import matplotlib.pyplot as plt     # ì‹œê°í™”(ì´ë¯¸ì§€ ê·¸ë¦¬ê¸°)ìš©

# 1. [ì‹œë“œ ê³ ì •]
tf.random.set_seed(777)

# 2. [í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •]
learning_rate = 0.001
batch_size = 100
training_epochs = 15
nb_classes = 10

# CIFAR-10ì˜ ì •ë‹µ ì´ë¦„í‘œ (0~9)
class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 
               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']

# 3. [ë°ì´í„° ë¡œë“œ - TFDS í™œìš©]
# batch_size=-1ë¡œ ì„¤ì •í•˜ë©´ ë°ì´í„°ì…‹ ì „ì²´ë¥¼ í•œ ë²ˆì— Numpy í˜•íƒœë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
print("ğŸ“¦ TFDSì—ì„œ CIFAR-10 ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤...")
ds_train, ds_test = tfds.load('cifar10', split=['train', 'test'], 
                              batch_size=-1, as_supervised=True)

# TFDSëŠ” í…ì„œ(Tensor) í˜•íƒœë¡œ ë°ì´í„°ë¥¼ ì¤ë‹ˆë‹¤. ì´ë¥¼ ìš°ë¦¬ê°€ ìµìˆ™í•œ Numpyë¡œ ë°”ê¿‰ë‹ˆë‹¤.
x_train, y_train = tfds.as_numpy(ds_train)
x_test, y_test = tfds.as_numpy(ds_test)

print(f"í•™ìŠµ ë°ì´í„° í˜•íƒœ: {x_train.shape}") # (50000, 32, 32, 3) -> ì»¬ëŸ¬ ì´ë¯¸ì§€ë¼ 3ì±„ë„!

# 4. [ë°ì´í„° ì „ì²˜ë¦¬]
# (1) 2ì°¨ì›(32x32x3) -> 1ì°¨ì›(3072) í‰íƒ„í™”
# ì»¬ëŸ¬ ì´ë¯¸ì§€ëŠ” í”½ì…€ ìˆ˜ê°€ í›¨ì”¬ ë§ìŠµë‹ˆë‹¤. (32 * 32 * 3 = 3072)
input_shape = 32 * 32 * 3
x_train_flat = x_train.reshape(x_train.shape[0], input_shape)
x_test_flat = x_test.reshape(x_test.shape[0], input_shape)

# (2) ì •ê·œí™” (Normalization) - 0~255 ê°’ì„ 0~1ë¡œ
x_train_flat = x_train_flat / 255.0
x_test_flat = x_test_flat / 255.0

# (3) ì›-í•« ì¸ì½”ë”©
y_train_onehot = tf.keras.utils.to_categorical(y_train, nb_classes)
y_test_onehot = tf.keras.utils.to_categorical(y_test, nb_classes)

# 5. [ëª¨ë¸ êµ¬ì„±] Xavier(Glorot) ì´ˆê¸°í™” ì ìš©
tf.model = tf.keras.Sequential()

# ì…ë ¥ì´ 3072ê°œë¡œ ëŠ˜ì–´ë‚¬ìœ¼ë¯€ë¡œ, ì€ë‹‰ì¸µ ë‰´ëŸ°ë„ 512ê°œë¡œ ëŠ˜ë ¤ì¤ë‹ˆë‹¤.
tf.model.add(tf.keras.layers.Dense(input_dim=input_shape, units=512, 
                                   kernel_initializer='glorot_normal', activation='relu'))
tf.model.add(tf.keras.layers.Dense(units=512, 
                                   kernel_initializer='glorot_normal', activation='relu'))
tf.model.add(tf.keras.layers.Dense(units=512, 
                                   kernel_initializer='glorot_normal', activation='relu'))
tf.model.add(tf.keras.layers.Dense(units=nb_classes, 
                                   kernel_initializer='glorot_normal', activation='softmax'))

# 6. [ì»´íŒŒì¼ ë° í•™ìŠµ]
tf.model.compile(loss='categorical_crossentropy',
                 optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                 metrics=['accuracy'])

print("\nğŸš€ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤ (ì»¬ëŸ¬ ì´ë¯¸ì§€ë¼ ì‹œê°„ì´ ì¡°ê¸ˆ ë” ê±¸ë¦½ë‹ˆë‹¤)...")
history = tf.model.fit(x_train_flat, y_train_onehot, batch_size=batch_size, epochs=training_epochs)

# 7. [ê²°ê³¼ ì‹œê°í™”] ì‹¤ì œ ì´ë¯¸ì§€ì™€ ì˜ˆì¸¡ ê²°ê³¼ ë³´ì—¬ì£¼ê¸°
print("\nğŸ¨ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ ëœë¤ìœ¼ë¡œ 15ê°œ ë½‘ê¸°
indices = np.random.choice(len(x_test), 15, replace=False)
predictions = tf.model.predict(x_test_flat[indices])

plt.figure(figsize=(15, 6)) # ì°½ í¬ê¸° ì¡°ì ˆ

for i, idx in enumerate(indices):
    plt.subplot(3, 5, i + 1) # 3ì¤„ 5ì¹¸ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
    
    # í‰íƒ„í™”ëœ ë°ì´í„°ë¥¼ ë‹¤ì‹œ 32x32x3 ì´ë¯¸ì§€ í˜•íƒœë¡œ ë˜ëŒë ¤ì•¼ ê·¸ë¦¼ì´ ê·¸ë ¤ì§‘ë‹ˆë‹¤.
    img = x_test[idx] 
    plt.imshow(img)
    
    # ì •ë‹µê³¼ ì˜ˆì¸¡ê°’ ë¹„êµ
    actual_idx = y_test[idx] if len(y_test.shape) == 1 else np.argmax(y_test[idx]) # ì›ë³¸ ë¼ë²¨
    pred_idx = np.argmax(predictions[i])
    
    label_actual = class_names[actual_idx]
    label_pred = class_names[pred_idx]
    
    # ë§ìœ¼ë©´ ì´ˆë¡ìƒ‰, í‹€ë¦¬ë©´ ë¹¨ê°„ìƒ‰ ê¸€ì”¨
    color = 'green' if actual_idx == pred_idx else 'red'
    
    plt.title(f"A: {label_actual}\nP: {label_pred}", color=color)
    plt.axis('off') # ì¶• ì—†ì• ê¸°

plt.tight_layout()
plt.show()

# 8. [ìµœì¢… ì •í™•ë„ í‰ê°€]
score = tf.model.evaluate(x_test_flat, y_test_onehot, verbose=0)
print(f"\nìµœì¢… ì •í™•ë„: {score[1]*100:.2f}%")
#==========================================================
# NN_xaviorë¥¼ TFDS ë°ì´í„°ì— ì ìš©ì‹œí‚¨ ê²°ê³¼ 
# MNISTëŠ” (28, 28, 1)ì´ì—ˆì§€ë§Œ CIFAR-10ì€ (32, 32, 3)ìœ¼ë¡œ ë°ì–´í„°ê°€ 4ë°° ì •ë„ ëŠ˜ì–´ë‚¨
# ìµœì¢… ì •í™•ë„: 46.19% í•™ìŠµì„ í•˜ê¸´ í–ˆì§€ë§Œ, ë‹¨ìˆœ ì‹ ê²½ë§ìœ¼ë¡œëŠ” ì»¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ”ë° í•œê³„ê°€ ìˆë‹¤.
# í•™ìŠµ ì ìˆ˜ì™€ ì‹¤ì „ ì ìˆ˜ì— 46.2% ì˜¤ì°¨ê°€ ë°œìƒí•´ì„œ ê³¼ì í•©ì˜ ì¡°ì§ì´ ë³´ì¸ë‹¤.
# ê°œì™€ ê³ ì–‘ì´ë¥¼ í˜¼ë™í•˜ê±°ë‚˜ íŠ¸ëŸ­ê³¼ ìŠ¹ìš©ì°¨ê´€ë ¨ ë¬¸ì œê°€ ë°œìƒí–ˆìŒ.
# í‰íƒ„í™” ê³¼ì •ì—ì„œ ìœ„ì¹˜ ì •ë³´ì˜ íŒŒê´´ì™€ ë°°ê²½ìƒ‰ì— ì˜ì¡´í•˜ëŠ” ë¬¸ì œê°€ ë°œìƒí–ˆë‹¤

# TFDSë¥¼ ì´ìš©í•´ ë” ë³µì¡í•œ ì»¬ë¦¬ ì´ë¯¸ì§€ì— Xavior ì´ˆê¸°í™”ë¥¼ ì ìš©ì‹œì¼œ í•™ìŠµì‹œì¼°ì§€ë§Œ,
# ì•„ì§ ì¶©ë¶„í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ì§€ ëª»í•œë‹¤.

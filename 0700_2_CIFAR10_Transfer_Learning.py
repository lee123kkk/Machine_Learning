# 0700_2_CIFAR10_Transfer_Learning

import tensorflow as tf
import datetime

# 1ï¸âƒ£ [ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬]
print("ğŸš€ CIFAR-10 ë°ì´í„° ë¡œë“œ ì¤‘...")
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()

# MobileNetV2 ì „ìš© ì „ì²˜ë¦¬ (0~1 ì •ê·œí™” ëŒ€ì‹  -1~1 ì‚¬ì´ë¡œ ê°’ì„ ë³€í™˜í•˜ì—¬ ëª¨ë¸ì— ìµœì í™”ì‹œí‚´)
x_train = tf.keras.applications.mobilenet_v2.preprocess_input(x_train.astype('float32'))
x_test = tf.keras.applications.mobilenet_v2.preprocess_input(x_test.astype('float32'))

nb_classes = 10
y_train = tf.keras.utils.to_categorical(y_train, nb_classes)
y_test = tf.keras.utils.to_categorical(y_test, nb_classes)

# 2ï¸âƒ£ [ì¼íƒ€ ê°•ì‚¬ ì˜ì…: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ]
# weights='imagenet': ìˆ˜ë°±ë§Œ ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ê¹¨ìš°ì¹œ 'ì‹œê°ì  ê·œì¹™'ì„ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
# include_top=False: ì›ë˜ ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ë¶„ë¥˜ê¸°(1000ê°œ ë¶„ë¥˜)ëŠ” ë–¼ì–´ë‚´ê³  'ëˆˆ(íŠ¹ì„± ì¶”ì¶œê¸°)'ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
print("ğŸ§  ì‚¬ì „ í•™ìŠµëœ MobileNetV2 ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...")
base_model = tf.keras.applications.MobileNetV2(input_shape=(96, 96, 3), 
                                               include_top=False, 
                                               weights='imagenet')

# â­ í•µì‹¬: ê°€ì ¸ì˜¨ ë‡Œì˜ ê¸°ì–µì´ ì§€ì›Œì§€ì§€ ì•Šë„ë¡ ê°€ì¤‘ì¹˜ë¥¼ ì–¼ë ¤ë²„ë¦½ë‹ˆë‹¤(Freeze). 
# ì´ë ‡ê²Œ í•˜ë©´ í•™ìŠµí•´ì•¼ í•  íŒŒë¼ë¯¸í„°ê°€ í™• ì¤„ì–´ë“¤ì–´ RTX 4060ì—ì„œ ìˆœì‹ê°„ì— í•™ìŠµì´ ëë‚©ë‹ˆë‹¤.
base_model.trainable = False 

# 3ï¸âƒ£ [ìš°ë¦¬ì˜ ëª©ì ì— ë§ëŠ” ìƒˆë¡œìš´ ëª¨ë¸ ì¡°ë¦½]
model = tf.keras.Sequential([
    # ëª…ì‹œì ì¸ ì…ë ¥ì¸µ (ê·¸ë˜í”„ ì¶”ì ì„ ê¹”ë”í•˜ê²Œ ë§Œë“¤ê¸° ìœ„í•¨)
    tf.keras.layers.InputLayer(input_shape=(32, 32, 3)),
    
    # íŒ: MobileNetV2ëŠ” 32x32 ì´ë¯¸ì§€ë³´ë‹¤ í° ì´ë¯¸ì§€ë¥¼ ë” ì˜ ë´…ë‹ˆë‹¤. 
    # í•´ìƒë„ë¥¼ 3ë°°(96x96)ë¡œ ê°•ì œë¡œ í‚¤ì›Œì„œ ë„£ì–´ì£¼ë©´ ì •í™•ë„ê°€ í›¨ì”¬ ì˜¬ë¼ê°‘ë‹ˆë‹¤.
    tf.keras.layers.UpSampling2D(size=(3, 3)),
    
    # ë–¼ì–´ì˜¨ ì¼íƒ€ ê°•ì‚¬ì˜ ë‡Œ(íŠ¹ì„± ì¶”ì¶œê¸°) ë¶€ì°©
    base_model,
    
    # ì¶”ì¶œëœ ìˆ˜ë§ì€ íŠ¹ì§•ë“¤ì„ í‰ê·  ë‚´ì–´ 1ì°¨ì›ìœ¼ë¡œ ì••ì¶• (Flattenë³´ë‹¤ íŒŒë¼ë¯¸í„°ê°€ í›¨ì”¬ ì ê³  íš¨ìœ¨ì ì„)
    tf.keras.layers.GlobalAveragePooling2D(),
    
    # ìš°ë¦¬ê°€ ì§ì ‘ í•™ìŠµì‹œí‚¬ ê¼¬ë¦¬ ë¶€ë¶„ (ìƒˆë¡œìš´ ë¶„ë¥˜ê¸°)
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(nb_classes, activation='softmax')
])

model.compile(loss='categorical_crossentropy',
              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              metrics=['accuracy'])
model.summary()

# 4ï¸âƒ£ [â­ìˆ˜ë™ ê·¸ë˜í”„ ì¶”ì  (Manual Graph Tracing)]
# Keras ì½œë°±ì˜ ë²„ê·¸(Malformed GraphDef)ë¥¼ í”¼í•˜ê¸° ìœ„í•´, ì§ì ‘ ëª¨ë¸ êµ¬ì¡°ë¥¼ ë…¹í™”í•´ì„œ í…ì„œë³´ë“œì— ì €ì¥í•©ë‹ˆë‹¤.
log_dir = "logs/transfer/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
writer = tf.summary.create_file_writer(log_dir)

print("\nğŸ“¹ í…ì„œë³´ë“œìš© ëª¨ë¸ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ë…¹í™”í•©ë‹ˆë‹¤...")
tf.summary.trace_on(graph=True, profiler=False)
dummy_input = tf.zeros((1, 32, 32, 3)) # ê°€ì§œ ë°ì´í„° 1ì¥
_ = model(dummy_input)                 # ëª¨ë¸ì— í†µê³¼ì‹œí‚¤ë©° íë¦„ ë…¹í™”

with writer.as_default():
    tf.summary.trace_export(name="transfer_learning_graph", step=0)
print("âœ… ê·¸ë˜í”„ ë…¹í™” ì™„ë£Œ!")

# 5ï¸âƒ£ [ì½œë°± í•¨ìˆ˜ ì„¤ì •]
# ì´ë¯¸ ìˆ˜ë™ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ì €ì¥í–ˆìœ¼ë¯€ë¡œ, write_graph=Falseë¡œ ì„¤ì •í•˜ì—¬ ì¶©ëŒì„ ë§‰ìŠµë‹ˆë‹¤.
tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, write_graph=False, histogram_freq=1)

checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(
    filepath='best_transfer_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1
)

# 6ï¸âƒ£ [í•™ìŠµ ìˆ˜í–‰]
# ì–¼ì–´ìˆëŠ” ëª¨ë¸ì€ í•™ìŠµí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì—í¬í¬ë‹¹ í•™ìŠµ ì†ë„ê°€ ë§¤ìš° ë¹ ë¦…ë‹ˆë‹¤. 10 ì—í¬í¬ë§Œ ëŒë ¤ë´…ë‹ˆë‹¤.
training_epochs = 10 
batch_size = 128

print("\nğŸš€ ì „ì´ í•™ìŠµ ì‹œì‘! (ë¶„ë¥˜ê¸° ë¶€ë¶„ë§Œ í•™ìŠµí•˜ë¯€ë¡œ ë§¤ìš° ë¹ ë¦…ë‹ˆë‹¤)...")
history = model.fit(x_train, y_train,
                    batch_size=batch_size,
                    epochs=training_epochs,
                    validation_data=(x_test, y_test),
                    callbacks=[tensorboard_cb, checkpoint_cb])

# 7ï¸âƒ£ [ìµœì¢… í‰ê°€]
print("\n" + "="*50)
evaluation = model.evaluate(x_test, y_test)
print(f"ìµœì¢… Loss: {evaluation[0]:.4f}")
print(f"ìµœì¢… ì‹¤ì „ ì •í™•ë„(Accuracy): {evaluation[1]*100:.2f}%")

#=========================================================
# ì „ì´ í•™ìŠµ
# MobileNetV2ë¥¼ í™œìš©í•œ ì „ì´ í•™ìŠµ
# ì›ë˜ í•™ìŠµë˜ì–´ ìˆëŠ” ë‚´ìš©ì„ ë°”íƒ€ì‘ë¡œ ë¶„ë¥˜ê¸° ë¶€ë¶„ë§Œ ìƒˆë¡œ í•™ìŠµ

# ì „ì²´ íŒŒë¼ë¯¸í„°ëŠ” 242ë§Œê°œì´ì§€ë§Œ í›ˆë ¨ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ëŠ” ìƒˆë¡œ ì¶”ê°€í•œ 16ë§Œê°œ ë¿ì´ë‹¤.
# MolieNetV2ë¥¼ freeze í–ˆê¸° ë•Œë¬¸ì— ì—í¬í¬ë‹¹ ì†Œìš” ì‹œê°„ì´ 7ì—ì„œ 8ì´ˆ ë°–ì— ë˜ì§€ ì•ŠëŠ”ë‹¤.
# ì •í™•ë„ ê·¸ã…ë˜í”„ê°€ ê³¼ì í•©ì—†ì´ ìš°ìƒí–¥í•˜ê³  ìˆë‹¤.
# ìµœì¢… ì •í™•ë„ê°€ 80.22%ê°€ ë‚˜ì™”ë‹¤.
# Lab 6 Softmax Classifier

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D # 3D ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•œ ë„êµ¬

# ê²°ê³¼ ì¬í˜„ì„ ìœ„í•œ ì‹œë“œ ê³ ì •
tf.random.set_seed(777)

# 1. [ë°ì´í„° ì¤€ë¹„]
# x_data: [ê³µë¶€ ì‹œê°„, ì¶œì„ ìˆ˜]
x_data = [[10, 5],
          [9, 5],
          [3, 2],
          [2, 4],
          [11, 1]]

# y_data: [Aë“±ê¸‰, Bë“±ê¸‰, Cë“±ê¸‰] (ì›-í•« ì¸ì½”ë”©)
# [1, 0, 0] -> Class 0 (A)
# [0, 1, 0] -> Class 1 (B)
# [0, 0, 1] -> Class 2 (C)
y_data = [[1, 0, 0],
          [1, 0, 0],
          [0, 1, 0],
          [0, 1, 0],
          [0, 0, 1]]

x_data = np.array(x_data, dtype=np.float32)
y_data = np.array(y_data, dtype=np.float32)

# í´ë˜ìŠ¤ ê°œìˆ˜ (3ê°œ)
nb_classes = 3

# 2. [ëª¨ë¸ êµ¬ì„±]
model = tf.keras.Sequential()
# ì…ë ¥ 2ê°œ -> ì¶œë ¥ 3ê°œ (Softmax)
model.add(tf.keras.layers.Dense(units=nb_classes, input_dim=2, activation='softmax'))

# 3. [ì»´íŒŒì¼]
# ì›-í•« ì¸ì½”ë”©ì´ë¯€ë¡œ categorical_crossentropy ì‚¬ìš©
model.compile(loss='categorical_crossentropy',
              optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),
              metrics=['accuracy'])

# 4. [í•™ìŠµ]
print("ğŸ—ï¸ ì¸ê³µì§€ëŠ¥ì´ 3D ì„±ì  ê³„ë‹¨ì„ ìŒ“ê³  ìˆìŠµë‹ˆë‹¤...")
history = model.fit(x_data, y_data, epochs=2000, verbose=0)
print("âœ… í•™ìŠµ ì™„ë£Œ!")

# ==========================================================
# 5. [3D ì‹œê°í™”] ê²°ì • ê²½ê³„(Decision Boundary) ê·¸ë¦¬ê¸°
# ==========================================================

# (1) ê·¸ë˜í”„ì˜ ë°”ë‹¥ ë©´ì (Grid) ë§Œë“¤ê¸°
x1_min, x1_max = x_data[:, 0].min() - 1, x_data[:, 0].max() + 1
x2_min, x2_max = x_data[:, 1].min() - 1, x_data[:, 1].max() + 1

# 0.1 ê°„ê²©ìœ¼ë¡œ ì´˜ì´˜í•˜ê²Œ ì¢Œí‘œ ìƒì„± (ë°”ë‘‘íŒ ë§Œë“¤ê¸°)
xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.1),
                       np.arange(x2_min, x2_max, 0.1))

# (2) ë°”ë‘‘íŒ ìœ„ì˜ ëª¨ë“  ì ì— ëŒ€í•´ ì˜ˆì¸¡í•˜ê¸°
# 2ì°¨ì› ë°”ë‘‘íŒì„ 1ì¤„ë¡œ ì­‰ í´ì„œ(ravel) ëª¨ë¸ì— ì…ë ¥
grid_points = np.c_[xx1.ravel(), xx2.ravel()]
pred_probs = model.predict(grid_points, verbose=0)

# ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ ë²ˆí˜¸(0, 1, 2)ë¥¼ ê°€ì ¸ì˜´ -> ì´ê²ƒì´ Zì¶•(ë†’ì´)ì´ ë¨
pred_labels = np.argmax(pred_probs, axis=1)

# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ë°”ë‘‘íŒ ëª¨ì–‘(2D)ìœ¼ë¡œ ë³µêµ¬
Z = pred_labels.reshape(xx1.shape)

# (3) 3D ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d') # 3D ì¶• ìƒì„±

# ê²°ì • ê²½ê³„ë©´(Surface) ê·¸ë¦¬ê¸°
# Zê°’(0, 1, 2)ì— ë”°ë¼ ë†’ì´ê°€ ë‹¤ë¥¸ ê³„ë‹¨ì‹ ì§€í˜•ì´ ê·¸ë ¤ì§‘ë‹ˆë‹¤.
# cmap='coolwarm': íŒŒë€ìƒ‰(0) ~ ë¹¨ê°„ìƒ‰(2)ìœ¼ë¡œ ìƒ‰ìƒ í‘œí˜„
ax.plot_surface(xx1, xx2, Z, alpha=0.3, cmap='coolwarm', edgecolor='none')

# (4) ì‹¤ì œ ë°ì´í„° ì  ì°ê¸°
# ì •ë‹µ(y_data)ì„ ìˆ«ìë¡œ ë³€í™˜ (0, 1, 2) -> ì ì˜ ë†’ì´(z)ë¡œ ì‚¬ìš©
y_label = np.argmax(y_data, axis=1)
label_names = {0:'Class A', 1:'Class B', 2:'Class C'}
colors = ['blue', 'green', 'red'] # 0:íŒŒë‘, 1:ì´ˆë¡, 2:ë¹¨ê°•

for i in range(nb_classes):
    # í•´ë‹¹ í´ë˜ìŠ¤ì¸ ë°ì´í„°ë§Œ ê³¨ë¼ë‚´ê¸°
    idx = (y_label == i)
    # 3D ì‚°ì ë„ ê·¸ë¦¬ê¸° (xs, ys, zs)
    ax.scatter(x_data[idx, 0], x_data[idx, 1], y_label[idx],
               c=colors[i], 
               s=100, 
               edgecolors='k', 
               label=label_names[i])

ax.set_xlabel('Study Hours (x1)')
ax.set_ylabel('Attendance (x2)')
ax.set_zlabel('Class (0, 1, 2)')
ax.set_title('3D Softmax Decision Boundary')
ax.legend()

plt.show()
#=============================================================================
# 3D ì…ì²´ ê³µê°„ì—ì„œ ì†Œí”„íŠ¸ ë§¥ìŠ¤ ë¶„ë¥˜ê¸°ì˜ ê²°ì • ê²½ê³„ë¥¼ ì‹œê°í™”í•˜ëŠ” ì˜ˆì œ
# ë†’ì´ë¥¼ í´ë˜ìŠ¤ë¡œ ì„¤ì •í•˜ì—¬ ì…ë ¥ ë°ì´í„°ì— ë”°ë¼ ì–´ë–¤ ë“±ê¸‰ì„ ì„ íƒí•´ì•¼ í•˜ëŠ”ì§€ ê³„ë‹¨ ëª¨í˜•ì˜ ì§€í˜•ìœ¼ë¡œ ë³´ì—¬ì¤€ë‹¤.
# ì†Œí”„íŠ¸ë§¥ìŠ¤ ë¶„ë¥˜ê¸°ëŠ” ì…ë ¥ ë°ì´í„°ì˜ íŠ¹ì§•ì„ ë°”íƒ€íƒ•ìœ¼ë¡œ ê° ë°ì´í„°ê°€ ì†í•´ì•¼ í•  ìµœì ì˜ í´ë˜ìŠ¤ë¥¼ ì…ì²´ì ìœ¼ë¡œ ê²°ì •í•œë‹¤.


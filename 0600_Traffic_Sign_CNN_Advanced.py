

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import numpy as np

# 1ï¸âƒ£ [ë°ì´í„° ë¡œë“œ] ë³€ê²½ëœ ë¶€ë¶„
print("ğŸš€ CIFAR-10 ì‚¬ë¬¼ ì¸ì‹ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...")
(ds_train, ds_test), ds_info = tfds.load(
    'cifar10',  # ğŸ‘ˆ 'gtsrb'ë¥¼ 'cifar10'ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤!
    split=['train', 'test'],
    with_info=True,
    as_supervised=True,
    data_dir='./my_tf_data',
    download=True 
)

# ì´ 43ì¢…ë¥˜ì˜ êµí†µ í‘œì§€íŒì´ ìˆìŠµë‹ˆë‹¤. (ì†ë„ ì œí•œ, ì§„ì… ê¸ˆì§€, ë©ˆì¶¤ ë“±)
nb_classes = ds_info.features['label'].num_classes
IMG_SIZE = 32 # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ 32x32 í¬ê¸°ë¡œ í†µì¼

# 2ï¸âƒ£ [ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜]
# ì‹¤ì „ ë°ì´í„°ëŠ” í¬ê¸°ê°€ ë‹¤ ë‹¤ë¥´ë¯€ë¡œ ê°•ì œë¡œ ë¦¬ì‚¬ì´ì¦ˆí•´ì•¼ ëª¨ë¸ì— ë„£ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
def preprocess(image, label):
    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE)) # 32x32ë¡œ í¬ê¸° í†µì¼
    image = image / 255.0                                # 0~1 ì •ê·œí™”
    label = tf.one_hot(label, depth=nb_classes)          # ì›-í•« ì¸ì½”ë”©
    return image, label

# ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶• (ë©”ëª¨ë¦¬ í­ë°œì„ ë§‰ê¸° ìœ„í•´ ë©ì–´ë¦¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬)
BATCH_SIZE = 64
train_data = ds_train.map(preprocess).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
test_data = ds_test.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

# 3ï¸âƒ£ [ëª¨ë¸ êµ¬ì„±] ì‹¤ì „í˜• CNN (Batch Normalization + Dropout ì¶”ê°€)
model = tf.keras.Sequential()

# Layer 1: íŠ¹ì„± ì¶”ì¶œ + ë°°ì¹˜ ì •ê·œí™”
model.add(tf.keras.layers.Conv2D(32, (3, 3), input_shape=(IMG_SIZE, IMG_SIZE, 3)))
# â­ ë°°ì¹˜ ì •ê·œí™”: ê° ì¸µì— ë“¤ì–´ê°€ëŠ” ë°ì´í„°ë¥¼ ê°€ì§€ëŸ°íˆ ì •ëˆí•˜ì—¬ í•™ìŠµ ì†ë„ì™€ ì•ˆì •ì„±ì„ ëŒ€í­ ëŒì–´ì˜¬ë¦½ë‹ˆë‹¤.
model.add(tf.keras.layers.BatchNormalization()) 
model.add(tf.keras.layers.Activation('relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))

# Layer 2: ê¹Šì€ íŠ¹ì„± ì¶”ì¶œ
model.add(tf.keras.layers.Conv2D(64, (3, 3)))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation('relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))

# Layer 3: ë¶„ë¥˜ê¸° (Fully Connected)
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(128))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation('relu'))

# â­ ë“œë¡­ì•„ì›ƒ: ë„ˆë¬´ ë˜‘ê°™ì´ ì™¸ìš°ì§€ ì•Šë„ë¡ ë‰´ëŸ°ì˜ 50%ë¥¼ ë•ë‹ˆë‹¤ (ê³¼ì í•© ë°©ì§€).
model.add(tf.keras.layers.Dropout(0.5)) 
model.add(tf.keras.layers.Dense(nb_classes, activation='softmax'))

# 4ï¸âƒ£ [ì»´íŒŒì¼] Optimizer ë¹„êµ (Adam vs SGD)
# SGD: ì²œì²œíˆ ê¼¼ê¼¼í•˜ê²Œ ì‚°ì„ ë‚´ë ¤ê°‘ë‹ˆë‹¤. ì„¤ì •(í•™ìŠµë¥  ë“±)ì„ ê¸°ê°€ ë§‰íˆê²Œ ë§ì¶”ë©´ ìµœê³  ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ë„ ìˆì§€ë§Œ íŠœë‹ì´ ë§¤ìš° ì–´ë µìŠµë‹ˆë‹¤.
# Adam: ìƒí™©ì— ë§ì¶° ë³´í­ì„ ì˜ë¦¬í•˜ê²Œ ì¡°ì ˆí•©ë‹ˆë‹¤. ì‹¤ë¬´ì—ì„œ ê°€ì¥ ê¸°ë³¸ì ì´ê³  ê°•ë ¥í•˜ê²Œ ì“°ì…ë‹ˆë‹¤. (ì—¬ê¸°ì„œëŠ” Adam ì‚¬ìš©)
model.compile(loss='categorical_crossentropy', 
              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), 
              metrics=['accuracy'])
model.summary()

# 5ï¸âƒ£ [í•™ìŠµ ìˆ˜í–‰]
training_epochs = 15
print("\nğŸš€ ììœ¨ì£¼í–‰ êµí†µ í‘œì§€íŒ ì¸ì‹ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
history = model.fit(train_data, epochs=training_epochs, validation_data=test_data)

# 6ï¸âƒ£ [ìµœì¢… í‰ê°€]
print("\n" + "="*50)
evaluation = model.evaluate(test_data)
print(f"ìµœì¢… Loss: {evaluation[0]:.4f}")
print(f"ìµœì¢… ì‹¤ì „ ì •í™•ë„(Accuracy): {evaluation[1]*100:.2f}%")
#===================================================================
# CNNì— ë°°ì¹˜ ì •ê·œí™”ì™€ ë“œë¡­ ì•„ì›ƒì„ ê²°í•©í•˜ì—¬ êµí†µ í‘œì§€íŒ ì¸ì‹ê¸° êµ¬ì¶•

# ì‚¬ìš©í•˜ë ¤ë˜ GTSRB ë°ì´í„° ì…‹ ì›ë³¸ ì„œë²„ì—ì„œ ë‹¤ìš´ë¡œë“œë¥¼ ì°¨ë‹¨í•˜ëŠ” ë¬¸ì œê°€ ë°œìƒí–ˆë‹¤.
# CIRAF-10 ë°ì´í„° ì…‹ìœ¼ë¡œ ëŒ€ì²´í•´ì„œ ì‚¬ìš©í–ˆë‹¤.

# ì´ íŒŒë¼ë¯¸í„° ìˆ˜: 31.6ë§Œê°œë¡œ ì´ì „ MNISTëª¨ë¸(1.2ë§Œê°œ)ë³´ë‹¤ ë¬´ê²ì§€ë§Œ 
# ì»¬ëŸ¬ ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ë‹´ì•„ë‚´ê¸°ì— íš¨ìœ¨ì ì¸ ê·œëª¨
# ë°°ì¹˜ ì •ê·œí™”: í•™ìŠµ ì†ë„ë¥¼ ë†’ì—¬ì£¼ê³ , ì•ˆì •ì ìœ¼ë¡œ ì˜¤ì°¨ë¥¼ ì¤„ì—¬ì¤Œ
# ë“œë¡­ì•„ì›ƒ: ê³¼ì í•© ë°©ì§€

# MLP(ë‹¨ìˆœ ì‹ ê²½ë§)ì—ì„œëŠ” CIFAR-10ì—ì„œ 46.19%ì˜ ì •í™•ë„ì˜€ì§€ë§Œ CNNì—ì„œëŠ” 70.71%ë¥¼ ë‹¬ì„±í–ˆë‹¤

# GPUì˜ ì‚¬ìšœëŸ‰ì„ ë³´ë©´ í…ì„œí”Œë¡œìš°ì— ì •ìƒì ìœ¼ë¡œ í• ë‹¹ë˜ì—ˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
# ì—í¬í¬ ë‹¹ ì•½ 2ì´ˆ ë‚´ì™¸ë¡œ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆë‹¤.

# CNN ëª¨ë¸ì„ í†µí•´ì„œ CIFAR-10 ë°ì´í„° ì…‹ì—ì„œ 70%ì´ìƒì˜ ë†’ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆë‹¤.